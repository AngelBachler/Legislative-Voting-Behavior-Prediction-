{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7786653",
   "metadata": {},
   "source": [
    "# 07: Procesamiento de Votaciones\n",
    "\n",
    "**Propósito:** Este *notebook* consolida todos los archivos `detalle.csv` (crudos, por período) de `data/01_raw/` en un único archivo maestro de votaciones.\n",
    "\n",
    "**Estrategia (Manejo de Memoria):**\n",
    "Debido a que el *dataset* final de votaciones tendrá millones de filas, no podemos cargar todos los CSV a la vez.\n",
    "\n",
    "1.  **Iterar:** Se itera por cada período.\n",
    "2.  **Cargar Chunk:** Se carga un solo `detalle.csv` en memoria.\n",
    "3.  **Procesar:** Se llama a `process_votaciones_chunk` (de `src/processing_utils.py`) para limpiar, mapear y estandarizar ese *chunk*.\n",
    "4.  **Anexar (Append):** El *chunk* limpio se anexa al archivo `votaciones_master_clean.parquet` en `data/02_processed/`.\n",
    "5.  **Liberar y Repetir.**\n",
    "\n",
    "**Dependencias:**\n",
    "* `data/01_raw/periodos_master.csv`\n",
    "* `data/01_raw/[periodo]/detalle.csv` (Múltiples archivos)\n",
    "\n",
    "**Salidas (Artifacts):**\n",
    "* `data/02_processed/votaciones_master_clean.parquet` (Un único archivo grande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc48f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import os # <-- Para eliminar el archivo antiguo\n",
    "from tqdm.notebook import tqdm\n",
    "import pyarrow as pa          # <-- AÑADIR ESTA LÍNEA\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# --- Configurar Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Importar lógica personalizada de /src ---\n",
    "sys.path.append('../') \n",
    "try:\n",
    "    from src.processing_utils import process_votaciones_chunk\n",
    "    from src.common_utils import sanitize_filename\n",
    "except ImportError as e:\n",
    "    logging.error(f\"ERROR: No se pudieron importar las funciones desde /src. {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225e07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:51:23,563 - INFO - Archivo de Salida: C:\\Users\\angel\\OneDrive\\Documents\\U\\2025-2\\Proyecto de Grado\\Legislative-Voting-Behavior-Prediction-\\data\\02_processed\\votaciones_master_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuración de Rutas y Constantes ---\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_DIR_RAW = ROOT / \"data\" / \"01_raw\"\n",
    "DATA_DIR_PROCESSED = ROOT / \"data\" / \"02_processed\"\n",
    "\n",
    "DATA_DIR_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dependencia\n",
    "MASTER_PERIOD_FILE = DATA_DIR_RAW / \"periodos_master.csv\"\n",
    "\n",
    "# Archivo de salida\n",
    "OUTPUT_FILE = DATA_DIR_PROCESSED / \"votaciones_master_clean.parquet\"\n",
    "\n",
    "logging.info(f\"Archivo de Salida: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f16b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:51:23,926 - INFO - No existe archivo Parquet anterior. Se creará uno nuevo.\n"
     ]
    }
   ],
   "source": [
    "if OUTPUT_FILE.exists():\n",
    "    logging.warning(f\"Eliminando archivo Parquet existente: {OUTPUT_FILE}\")\n",
    "    try:\n",
    "        os.remove(OUTPUT_FILE)\n",
    "        logging.info(\"Archivo antiguo eliminado.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"No se pudo eliminar el archivo. Verifique los permisos. Error: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    logging.info(\"No existe archivo Parquet anterior. Se creará uno nuevo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1461510",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 2. Carga de Dependencias (Períodos)\n",
    "\n",
    "Cargamos la lista maestra de períodos para saber qué carpetas iterar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca76a38-cba7-4684-b133-4a9cf58c6463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:51:24,688 - INFO - Se cargó la lista maestra de 10 períodos.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_periodos = pd.read_csv(MASTER_PERIOD_FILE)\n",
    "    logging.info(f\"Se cargó la lista maestra de {len(df_periodos)} períodos.\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"ERROR FATAL: No se encontró {MASTER_PERIOD_FILE}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0a055",
   "metadata": {},
   "source": [
    "## 3. Bucle Principal de Procesamiento (Chunking)\n",
    "\n",
    "Iteramos sobre cada período, cargamos su `detalle.csv`, lo procesamos en memoria y lo anexamos al archivo Parquet en el disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda9ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:52:26,185 - INFO - Iniciando procesamiento de votaciones para 10 períodos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21b0202cb524273a0ed7567b0ad4ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando Períodos:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:52:26,199 - WARNING - No se encontró C:\\Users\\angel\\OneDrive\\Documents\\U\\2025-2\\Proyecto de Grado\\Legislative-Voting-Behavior-Prediction-\\data\\01_raw\\1965-1969\\detalle.csv, saltando período 1965-1969.\n",
      "2025-10-29 12:52:26,200 - WARNING - No se encontró C:\\Users\\angel\\OneDrive\\Documents\\U\\2025-2\\Proyecto de Grado\\Legislative-Voting-Behavior-Prediction-\\data\\01_raw\\1990-1994\\detalle.csv, saltando período 1990-1994.\n",
      "2025-10-29 12:52:26,202 - WARNING - No se encontró C:\\Users\\angel\\OneDrive\\Documents\\U\\2025-2\\Proyecto de Grado\\Legislative-Voting-Behavior-Prediction-\\data\\01_raw\\1994-1998\\detalle.csv, saltando período 1994-1998.\n",
      "2025-10-29 12:52:26,203 - WARNING - No se encontró C:\\Users\\angel\\OneDrive\\Documents\\U\\2025-2\\Proyecto de Grado\\Legislative-Voting-Behavior-Prediction-\\data\\01_raw\\1998-2002\\detalle.csv, saltando período 1998-2002.\n",
      "2025-10-29 12:52:26,203 - INFO - --- Procesando Chunk: 2002-2006 ---\n",
      "2025-10-29 12:52:27,227 - INFO - Filtrando 'Proyectos de Ley' para 2002-2006...\n",
      "2025-10-29 12:52:27,376 - INFO - Se encontraron 167005 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:27,906 - INFO - ✓ Anexadas 167005 filas de 2002-2006.\n",
      "2025-10-29 12:52:27,907 - INFO - --- Procesando Chunk: 2006-2010 ---\n",
      "2025-10-29 12:52:29,219 - INFO - Filtrando 'Proyectos de Ley' para 2006-2010...\n",
      "2025-10-29 12:52:29,379 - INFO - Se encontraron 183983 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:30,004 - INFO - ✓ Anexadas 183983 filas de 2006-2010.\n",
      "2025-10-29 12:52:30,006 - INFO - --- Procesando Chunk: 2010-2014 ---\n",
      "2025-10-29 12:52:31,944 - INFO - Filtrando 'Proyectos de Ley' para 2010-2014...\n",
      "2025-10-29 12:52:32,179 - INFO - Se encontraron 292206 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:33,043 - INFO - ✓ Anexadas 292206 filas de 2010-2014.\n",
      "2025-10-29 12:52:33,044 - INFO - --- Procesando Chunk: 2014-2018 ---\n",
      "2025-10-29 12:52:35,135 - INFO - Filtrando 'Proyectos de Ley' para 2014-2018...\n",
      "2025-10-29 12:52:35,410 - INFO - Se encontraron 312521 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:36,563 - INFO - ✓ Anexadas 312521 filas de 2014-2018.\n",
      "2025-10-29 12:52:36,564 - INFO - --- Procesando Chunk: 2018-2022 ---\n",
      "2025-10-29 12:52:40,456 - INFO - Filtrando 'Proyectos de Ley' para 2018-2022...\n",
      "2025-10-29 12:52:40,942 - INFO - Se encontraron 466378 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:42,518 - INFO - ✓ Anexadas 466378 filas de 2018-2022.\n",
      "2025-10-29 12:52:42,520 - INFO - --- Procesando Chunk: 2022-2026 ---\n",
      "2025-10-29 12:52:46,955 - INFO - Filtrando 'Proyectos de Ley' para 2022-2026...\n",
      "2025-10-29 12:52:47,453 - INFO - Se encontraron 504657 votaciones de 'Proyectos de Ley'.\n",
      "2025-10-29 12:52:49,073 - INFO - ✓ Anexadas 504657 filas de 2022-2026.\n",
      "2025-10-29 12:52:49,075 - INFO - --- Procesamiento de votaciones finalizado ---\n",
      "2025-10-29 12:52:49,075 - INFO - Escritor Parquet cerrado. Total de filas procesadas: 1926750\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Iniciando procesamiento de votaciones para {len(df_periodos)} períodos...\")\n",
    "total_rows_processed = 0\n",
    "\n",
    "# --- 1. Inicializar el 'Writer' de Parquet ---\n",
    "writer = None\n",
    "global_schema = None\n",
    "\n",
    "try:\n",
    "    for row in tqdm(df_periodos.itertuples(), total=len(df_periodos), desc=\"Procesando Períodos\"):\n",
    "        \n",
    "        periodo_nombre = row.Nombre\n",
    "        carpeta_periodo = DATA_DIR_RAW / sanitize_filename(periodo_nombre)\n",
    "        ruta_detalle = carpeta_periodo / \"detalle.csv\"\n",
    "        \n",
    "        if not ruta_detalle.exists():\n",
    "            logging.warning(f\"No se encontró {ruta_detalle}, saltando período {periodo_nombre}.\")\n",
    "            continue\n",
    "            \n",
    "        logging.info(f\"--- Procesando Chunk: {periodo_nombre} ---\")\n",
    "        \n",
    "        # 1. Cargar Chunk\n",
    "        df_raw = pd.read_csv(ruta_detalle, low_memory=False)\n",
    "        \n",
    "        # 2. Procesar Chunk \n",
    "        df_clean = process_votaciones_chunk(df_raw, periodo_nombre)\n",
    "        \n",
    "        if df_clean.empty:\n",
    "            logging.warning(f\"Chunk limpio está vacío para {periodo_nombre}. No se anexa nada.\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Convertir el chunk de Pandas a una Tabla de PyArrow\n",
    "        table = pa.Table.from_pandas(df_clean)\n",
    "        \n",
    "        # --- 4. Lógica de Escritura (Append) ---\n",
    "        if writer is None:\n",
    "            # 4a. Guardar el schema y abrir el 'writer'\n",
    "            global_schema = table.schema\n",
    "            writer = pq.ParquetWriter(OUTPUT_FILE, global_schema)\n",
    "            \n",
    "            writer.write_table(table)\n",
    "        else:\n",
    "            # 4b. Escribir el chunk\n",
    "            writer.write_table(table.cast(global_schema))\n",
    "\n",
    "        total_rows_processed += len(df_clean)\n",
    "        logging.info(f\"Anexadas {len(df_clean)} filas de {periodo_nombre}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Capturar el período problemático en el mensaje de error\n",
    "    logging.error(f\"ERROR FATAL al procesar período {periodo_nombre}: {e}\", exc_info=True)\n",
    "finally:\n",
    "    # --- 5. (CRÍTICO) Cerrar el 'Writer' ---\n",
    "    if writer:\n",
    "        writer.close()\n",
    "        logging.info(\"--- Procesamiento de votaciones finalizado ---\")\n",
    "        logging.info(f\"Escritor Parquet cerrado. Total de filas procesadas: {total_rows_processed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
