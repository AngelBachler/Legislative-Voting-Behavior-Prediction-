{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1d9563",
   "metadata": {},
   "source": [
    "# 09: Ensamblaje y Creación de Features\n",
    "\n",
    "**Propósito:** Este es el *notebook* final del pipeline de datos. Su objetivo es tomar los tres *datasets* maestros limpios de `data/02_processed/` y unirlos en un único *dataset* analítico listo para el modelamiento (`analytical_dataset.parquet`).\n",
    "\n",
    "**Proceso (La \"Gran Fusión\"):**\n",
    "1.  **Cargar:** Cargar `diputados...`, `votaciones...`, `boletines...` y el archivo externo `colegios_chile.csv`.\n",
    "2.  **Enriquecer Boletines:** Aplicar **Multi-Hot Encoding** a `boletines_master` para transformar `ambitos_json` en columnas binarias (ej. `ambito_salud`, `ambito_economia`).\n",
    "3.  **Enriquecer Diputados:**\n",
    "    * Hacer `merge` con `colegios_chile.csv` para obtener la `dependencia` (Público/Privado).\n",
    "    * Calcular `antiguedad_partido_anios` usando las fechas de inicio de período y militancia.\n",
    "4.  **Ensamblar:** Unir las tres tablas enriquecidas. La tabla `votaciones_master` es nuestra \"tabla de hechos\" (la base) que une todo.\n",
    "5.  **Guardar:** Guardar el *dataset* final en `data/03_final/`.\n",
    "\n",
    "**Dependencias:**\n",
    "* `data/02_processed/diputados_periodo_master_clean.parquet`\n",
    "* `data/02_processed/votaciones_master_clean.parquet`\n",
    "* `data/02_processed/boletines_master_clean.parquet`\n",
    "* `data/01_raw/colegios_chile.csv` (O la ruta a tu archivo de colegios)\n",
    "\n",
    "**Salidas (Artifacts):**\n",
    "* `data/03_final/analytical_dataset.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c9699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 10:32:05,973 - ERROR - ERROR: No se pudo importar desde /src. cannot import name 'Sentinel' from 'typing_extensions' (/home/angel/.local/lib/python3.10/site-packages/typing_extensions.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Sentinel' from 'typing_extensions' (/home/angel/.local/lib/python3.10/site-packages/typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Necesitamos la función de normalizar texto para el merge de colegios\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_string\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     18\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: No se pudo importar desde /src. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/OneDrive/Documents/U/2025-2/Proyecto de Grado/Legislative-Voting-Behavior-Prediction-/notebooks/../src/common_utils.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m OllamaClient \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlistar_ops\u001b[39m(wsdl_url):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Lista las operaciones disponibles en un servicio SOAP dado su WSDL.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Útil para explorar endpoints de la Cámara de Diputados o del Senado.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ollama/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncClient, Client\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m   ChatResponse,\n\u001b[1;32m      4\u001b[0m   EmbeddingsResponse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m   WebSearchResponse,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsyncClient\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChatResponse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWebSearchResponse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ollama/_client.py:26\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m   Any,\n\u001b[1;32m     12\u001b[0m   Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m   overload,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01manyio\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonSchemaValue\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_function_to_tool\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m9\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_migration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getattr_migration\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION, _ensure_pydantic_core_version\n\u001b[1;32m      8\u001b[0m _ensure_pydantic_core_version()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/_migration.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticDeprecatedSince20\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_short\n\u001b[1;32m      8\u001b[0m MOVED_IN_V2 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic.utils:version_info\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic.version:version_info\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic.error_wrappers:ValidationError\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic:ValidationError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic.generics:GenericModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic.BaseModel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/warnings.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Pydantic-specific warnings.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations \u001b[38;5;28;01mas\u001b[39;00m _annotations\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_short\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPydanticDeprecatedSince20\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPydanticDeprecatedSince26\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTypedDictExtraConfigWarning\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPydanticDeprecationWarning\u001b[39;00m(\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/version.py:7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations \u001b[38;5;28;01mas\u001b[39;00m _annotations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m __pydantic_core_version__\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERSION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion_info\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m VERSION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.12.4\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic_core/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any \u001b[38;5;28;01mas\u001b[39;00m _Any\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sentinel\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     ArgsKwargs,\n\u001b[1;32m     10\u001b[0m     MultiHostUrl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     to_jsonable_python,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sentinel' from 'typing_extensions' (/home/angel/.local/lib/python3.10/site-packages/typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json # Para parsear los ámbitos\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # <-- La herramienta clave\n",
    "\n",
    "# --- Configurar Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Importar lógica personalizada de /src ---\n",
    "sys.path.append('../') \n",
    "try:\n",
    "    # Necesitamos la función de normalizar texto para el merge de colegios\n",
    "    from src.common_utils import normalize_string\n",
    "except ImportError as e:\n",
    "    logging.error(f\"ERROR: No se pudo importar desde /src. {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0df429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuración de Rutas y Constantes ---\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_DIR_PROCESSED = ROOT / \"data\" / \"02_processed\"\n",
    "DATA_DIR_FINAL = ROOT / \"data\" / \"03_final\"\n",
    "\n",
    "# (Directorio de donde cargas tu archivo de colegios)\n",
    "DATA_DIR_RAW = ROOT / \"data\" / \"01_raw\" \n",
    "\n",
    "# Asegurarse que el directorio de salida exista\n",
    "DATA_DIR_FINAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Archivos de Entrada ---\n",
    "DIPUTADOS_FILE = DATA_DIR_PROCESSED / \"diputados_master_clean.parquet\"\n",
    "VOTACIONES_FILE = DATA_DIR_PROCESSED / \"votaciones_master_clean.parquet\"\n",
    "BOLETINES_FILE = DATA_DIR_PROCESSED / \"boletines_master_clean.parquet\"\n",
    "COLEGIOS_FILE = DATA_DIR_RAW / \"colegios_chile.csv\" \n",
    "\n",
    "# --- Archivo de Salida ---\n",
    "OUTPUT_FILE = DATA_DIR_FINAL / \"analytical_dataset.parquet\"\n",
    "\n",
    "logging.info(f\"Directorio Procesado: {DATA_DIR_PROCESSED}\")\n",
    "logging.info(f\"Directorio Final: {DATA_DIR_FINAL}\")\n",
    "logging.info(f\"Archivo de Salida: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2669b",
   "metadata": {},
   "source": [
    "## 1. Cargar Datasets Maestros\n",
    "\n",
    "Cargamos las tres tablas maestras de la capa `02_processed` y cualquier BBDD externa (como la de colegios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Cargando datasets maestros...\")\n",
    "\n",
    "try:\n",
    "    df_diputados = pd.read_parquet(DIPUTADOS_FILE)\n",
    "    df_votaciones = pd.read_parquet(VOTACIONES_FILE)\n",
    "    df_boletines = pd.read_parquet(BOLETINES_FILE)\n",
    "    \n",
    "    logging.info(f\"Diputados cargados: {df_diputados.shape}\")\n",
    "    logging.info(f\"Votaciones cargadas: {df_votaciones.shape}\")\n",
    "    logging.info(f\"Boletines cargados: {df_boletines.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"ERROR: No se encontró un archivo maestro en {DATA_DIR_PROCESSED}. {e}\")\n",
    "    logging.error(\"Asegúrese de haber ejecutado los notebooks 06, 07 y 08.\")\n",
    "    raise\n",
    "\n",
    "# --- Cargar BBDD Externa de Colegios ---\n",
    "try:\n",
    "    df_colegios_db = pd.read_csv(\n",
    "        COLEGIOS_FILE,\n",
    "        sep=\";\",              # el Mineduc casi siempre usa punto y coma\n",
    "        encoding=\"latin-1\",   # evita problemas con tildes y ñ\n",
    "        on_bad_lines=\"skip\",  # salta filas con errores\n",
    "        engine=\"python\"       # más tolerante que el parser por defecto\n",
    "    )\n",
    "    logging.info(f\"BBDD Externa de Colegios cargada: {df_colegios_db.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.warning(f\"WARNING: No se encontró el archivo de colegios en {COLEGIOS_FILE}.\")\n",
    "    logging.warning(\"La feature 'dependencia_colegio' será 'Desconocida'.\")\n",
    "    df_colegios_db = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec64d8",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering: Boletines (Ámbitos Multi-Hot)\n",
    "\n",
    "Transformamos la columna `ambitos_json` (que contiene listas) en 13 columnas binarias (Multi-Hot Encoding), una por cada ámbito temático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd634f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Iniciando Multi-Hot Encoding de ámbitos...\")\n",
    "\n",
    "# 1. Convertir el string JSON de nuevo a una lista de Python\n",
    "# (Usamos .apply(json.loads) sobre la columna que guardamos)\n",
    "df_boletines['ambitos_list'] = df_boletines['ambitos_json'].apply(json.loads)\n",
    "\n",
    "# 2. Inicializar el \"codificador\"\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# 3. Aplicar el Multi-Hot Encoding\n",
    "df_ambitos_hot = pd.DataFrame(\n",
    "    mlb.fit_transform(df_boletines['ambitos_list']),\n",
    "    columns=mlb.classes_, # Nombra las columnas automáticamente\n",
    "    index=df_boletines.index\n",
    ")\n",
    "\n",
    "# 4. Añadir un prefijo para claridad\n",
    "df_ambitos_hot = df_ambitos_hot.add_prefix('ambito_')\n",
    "\n",
    "# 5. Unir las nuevas columnas al DataFrame de boletines\n",
    "df_boletines_enriquecido = df_boletines.join(df_ambitos_hot)\n",
    "\n",
    "# 6. Limpiar las columnas originales y la de 'no cumple'\n",
    "cols_to_drop = ['ambitos_json', 'ambitos_list']\n",
    "if 'ambito_no cumple' in df_boletines_enriquecido.columns:\n",
    "    cols_to_drop.append('ambito_no cumple')\n",
    "\n",
    "df_boletines_enriquecido = df_boletines_enriquecido.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "logging.info(\"Features de ámbitos creadas (Multi-Hot).\")\n",
    "display(df_boletines_enriquecido.filter(like='ambito_').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15f88b",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering: Diputados (Antigüedad y Colegios)\n",
    "\n",
    "Enriquecemos el dataset maestro de diputados con las *features* externas e internas que definimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253cf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Iniciando Feature Engineering en Diputados...\")\n",
    "df_diputados_enriquecido = df_diputados.copy()\n",
    "\n",
    "# --- 3a. Feature: Dependencia del Colegio ---\n",
    "if df_colegios_db is not None:\n",
    "    logging.info(\"Calculando 'dependencia_colegio'...\")\n",
    "    # Normalizar la llave en la BBDD de colegios\n",
    "    df_colegios_db['colegio_merge_key'] = df_colegios_db['NOM_RBD'].apply(normalize_string)\n",
    "    \n",
    "    # Seleccionar solo las columnas necesarias y eliminar duplicados\n",
    "    df_colegios_lookup = df_colegios_db[['colegio_merge_key', 'COD_DEPE']].drop_duplicates()\n",
    "    df_unique = (\n",
    "        df_diputados_enriquecido[[\"colegio_merge_key\"]]\n",
    "        .drop_duplicates()\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df_unique[[\"match_fuzzy\", \"score\", \"dependencia_oficial\"]] = df_unique[\"colegio_merge_key\"].apply(\n",
    "    lambda x: pd.Series(find_dependencia(x, df_colegios_lookup))\n",
    "    )\n",
    "    \n",
    "    # Hacemos el merge\n",
    "    df_diputados_enriquecido = pd.merge(\n",
    "        df_diputados_enriquecido,\n",
    "        df_unique,\n",
    "        on='colegio_merge_key',\n",
    "        how='left'\n",
    "    )\n",
    "    df_diputados_enriquecido['dependencia_colegio'] = df_diputados_enriquecido['dependencia_oficial'].fillna('Desconocida')\n",
    "    df_diputados_enriquecido = df_diputados_enriquecido.drop(columns=['dependencia_oficial'])\n",
    "else:\n",
    "    df_diputados_enriquecido['dependencia_colegio'] = 'Desconocida'\n",
    "\n",
    "\n",
    "# --- 3b. Feature: Antigüedad en el Partido ---\n",
    "logging.info(\"Calculando 'antiguedad_partido_anios'...\")\n",
    "if 'militancia_fecha_inicio' in df_diputados_enriquecido.columns:\n",
    "    # Asegurar que sean datetime\n",
    "    f_inicio_periodo = pd.to_datetime(df_diputados_enriquecido['periodo_fecha_inicio'], errors='coerce')\n",
    "    f_inicio_militancia = pd.to_datetime(df_diputados_enriquecido['militancia_fecha_inicio'], errors='coerce')\n",
    "    \n",
    "    # Calcular diferencia en días y luego en años\n",
    "    time_diff_days = (f_inicio_periodo - f_inicio_militancia).dt.days\n",
    "    df_diputados_enriquecido['antiguedad_partido_anios'] = time_diff_days / 365.25\n",
    "    \n",
    "    # Manejar valores negativos (si militancia fue *después* de iniciar período)\n",
    "    df_diputados_enriquecido.loc[df_diputados_enriquecido['antiguedad_partido_anios'] < 0, 'antiguedad_partido_anios'] = 0\n",
    "else:\n",
    "    logging.warning(\"No se encontró 'militancia_fecha_inicio', feature 'antiguedad' será NaN.\")\n",
    "    df_diputados_enriquecido['antiguedad_partido_anios'] = np.nan\n",
    "\n",
    "logging.info(\"DataFrame de Diputados enriquecido.\")\n",
    "display(df_diputados_enriquecido[['diputado_id', 'dependencia_colegio', 'antiguedad_partido_anios']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diputados_enriquecido[['diputado_id', 'colegio_raw', 'dependencia_colegio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465890d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diputados_enriquecido['dependencia_colegio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3e72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
